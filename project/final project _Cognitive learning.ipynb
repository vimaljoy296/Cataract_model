{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cataract Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\conda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import Necessary Libraries \n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your dataset\n",
    "dataset_dir = \"C:/Cognitive Learning/Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1007\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all image files in the dataset directory\n",
    "all_images = []\n",
    "for root, dirs, files in os.walk(dataset_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".png\"):\n",
    "            all_images.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"Number of images: {len(all_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels based on folder names (assuming binary classification)\n",
    "labels = [1 if \"cataract\" in img else 0 for img in all_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with file paths and labels\n",
    "df = pd.DataFrame({'filename': all_images, 'label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to strings\n",
    "df['label'] = df['label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions and batch size\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Normal Images: 603\n",
      "Number of Cataract Images: 404\n"
     ]
    }
   ],
   "source": [
    "# Count the number of images in each category\n",
    "normal_count = df[df['label'] == '0'].shape[0]\n",
    "cataract_count = df[df['label'] == '1'].shape[0]\n",
    "\n",
    "print(f\"Number of Normal Images: {normal_count}\")\n",
    "print(f\"Number of Cataract Images: {cataract_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for the training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling for the test set\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 805 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    " #Load and augment training data\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load and rescale test data\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\conda\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\conda\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Increase model complexity with additional layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\conda\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\conda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\conda\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "25/25 [==============================] - 173s 7s/step - loss: 2.4863 - accuracy: 0.5498 - val_loss: 0.5396 - val_accuracy: 0.7396\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 157s 6s/step - loss: 1.2361 - accuracy: 0.6339 - val_loss: 0.4264 - val_accuracy: 0.8021\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 166s 7s/step - loss: 0.7336 - accuracy: 0.6921 - val_loss: 0.4534 - val_accuracy: 0.8542\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 167s 7s/step - loss: 0.5979 - accuracy: 0.7180 - val_loss: 0.4078 - val_accuracy: 0.8490\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 170s 7s/step - loss: 0.5159 - accuracy: 0.7490 - val_loss: 0.3631 - val_accuracy: 0.8594\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 195s 8s/step - loss: 0.4470 - accuracy: 0.7930 - val_loss: 0.3084 - val_accuracy: 0.8698\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 189s 8s/step - loss: 0.4146 - accuracy: 0.7930 - val_loss: 0.3913 - val_accuracy: 0.8333\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 188s 8s/step - loss: 0.3890 - accuracy: 0.8215 - val_loss: 0.2974 - val_accuracy: 0.8490\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 148s 6s/step - loss: 0.3556 - accuracy: 0.8512 - val_loss: 0.2737 - val_accuracy: 0.8594\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 165s 6s/step - loss: 0.3071 - accuracy: 0.8629 - val_loss: 0.2532 - val_accuracy: 0.8958\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 194s 8s/step - loss: 0.3342 - accuracy: 0.8577 - val_loss: 0.2384 - val_accuracy: 0.9583\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 185s 7s/step - loss: 0.3265 - accuracy: 0.8590 - val_loss: 0.2147 - val_accuracy: 0.9479\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 203s 8s/step - loss: 0.3205 - accuracy: 0.8590 - val_loss: 0.2241 - val_accuracy: 0.9635\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 177s 7s/step - loss: 0.2731 - accuracy: 0.8875 - val_loss: 0.1977 - val_accuracy: 0.9479\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 191s 8s/step - loss: 0.2377 - accuracy: 0.9146 - val_loss: 0.2009 - val_accuracy: 0.9531\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 142s 6s/step - loss: 0.2509 - accuracy: 0.8939 - val_loss: 0.2668 - val_accuracy: 0.8906\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 165s 7s/step - loss: 0.2670 - accuracy: 0.8965 - val_loss: 0.2011 - val_accuracy: 0.9531\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 147s 6s/step - loss: 0.3350 - accuracy: 0.8629 - val_loss: 0.2682 - val_accuracy: 0.8750\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 158s 6s/step - loss: 0.2941 - accuracy: 0.8758 - val_loss: 0.2088 - val_accuracy: 0.9479\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 134s 5s/step - loss: 0.2555 - accuracy: 0.8926 - val_loss: 0.2108 - val_accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "# Increase the number of epochs\n",
    "epochs = 20\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_df) // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_df) // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 25s 3s/step - loss: 0.2090 - accuracy: 0.9356\n",
      "Test Accuracy: 93.56%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {accuracy[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model with a different name\n",
    "model.save('New_cataract_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, you can save it in the same folder as the dataset\n",
    "model.save(os.path.join(dataset_dir, 'New_cataract_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
